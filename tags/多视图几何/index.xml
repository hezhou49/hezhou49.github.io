<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>多视图几何 | FEZZY</title>
    <link>https://hezhou49.github.io/tags/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95/</link>
      <atom:link href="https://hezhou49.github.io/tags/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95/index.xml" rel="self" type="application/rss+xml" />
    <description>多视图几何</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 14 Apr 2021 02:23:00 +0800</lastBuildDate>
    <image>
      <url>https://hezhou49.github.io/media/icon_hu1c8e88b8ad59f9a914752996b889ae01_459483_512x512_fill_lanczos_center_3.png</url>
      <title>多视图几何</title>
      <link>https://hezhou49.github.io/tags/%E5%A4%9A%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95/</link>
    </image>
    
    <item>
      <title>射影变换与二视图几何</title>
      <link>https://hezhou49.github.io/docs/2d%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%B0%84%E5%BD%B1%E5%8F%98%E6%8D%A2%E4%B8%8E%E4%BA%8C%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95/</link>
      <pubDate>Wed, 14 Apr 2021 02:23:00 +0800</pubDate>
      <guid>https://hezhou49.github.io/docs/2d%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E5%B0%84%E5%BD%B1%E5%8F%98%E6%8D%A2%E4%B8%8E%E4%BA%8C%E8%A7%86%E5%9B%BE%E5%87%A0%E4%BD%95/</guid>
      <description>&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;《计算机视觉中的多视图几何》 第二版 （太数学了）&lt;/li&gt;
&lt;li&gt;基于局部特征的图像与点云配准研究[D]&lt;/li&gt;
&lt;li&gt;《视觉SLAM 14讲》&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/102022619&#34;&gt;知乎：射影平面的直观理解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%8D%95%E5%BA%94%E6%80%A7&#34;&gt;维基百科：单应性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.html&#34;&gt;opencv: Feature Matching + Homography to find Objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/sunny-li/p/7500541.html&#34;&gt;二视图从运动到结构&amp;mdash;-对极几何和基础矩阵&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;射影空间与射影变换&#34;&gt;射影空间与射影变换&lt;/h3&gt;
&lt;h4 id=&#34;射影空间&#34;&gt;射影空间&lt;/h4&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;齐次坐标&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321114417446.png&#34; alt=&#34;image-20220321114417446&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;点、直线的齐次表示&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321115621439.png&#34; alt=&#34;image-20220321115621439&#34;  /&gt;
&lt;p&gt;&lt;strong&gt;射影空间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;u&gt;n维射影空间用n+1维（除去全0）齐次向量组成。&lt;/u&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/102022619&#34;&gt;知乎：射影平面的直观理解&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;射影空间只是一组齐次向量的集合，它是为了方便运算而被制造出来，其实没有必要去研究他的物理或几何意义，重要的是关注射影变换&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;射影变换&#34;&gt;射影变换&lt;/h4&gt;
&lt;p&gt;射影空间是最&lt;strong&gt;一般&lt;/strong&gt;的空间变换。&lt;/p&gt;
&lt;p&gt;多视图几何几何给出的比较专业的定义如下，分为几何定义与代数定义。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/20220321152854.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%8D%95%E5%BA%94%E6%80%A7&#34;&gt;维基百科：单应性&lt;/a&gt;在计算机视觉领域中，&lt;strong&gt;空间中同一平面的任意两幅图像&lt;/strong&gt;通过单应性关联在一起（假定是针孔相机）。比如,一个物体可以通过旋转相机镜头获取两张不同的照片(这两张照片的内容不一定要完全对应,部分对应即可),我们可以把单应性设为一个二维矩阵M,那么照片1乘以M就是照片2。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;基于局部特征的图像与点云配准研究[D]中，关于2D射影变换的描述：（其内容几乎来自多视图几何一书）&lt;/p&gt;
&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321150106448.png&#34; alt=&#34;image-20220321150106448&#34; style=&#34;zoom: 67%;&#34; /&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321150136237.png&#34; alt=&#34;image-20220321150136237&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321150512847.png&#34; alt=&#34;image-20220321150512847&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;关于透视变换（perspective）与射影变换（projective）的区别：很多地方并不区分透视变换与射影变换。&lt;/p&gt;
&lt;p&gt;透视变换是射影变换的一种特殊场景。（参考书P25）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321155655449.png&#34; alt=&#34;image-20220321155655449&#34;&gt;&lt;/p&gt;
&lt;p&gt;区别：如图，两个透视变换的复合一般不是透视变换，而是射影变换。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321160030395.png&#34; alt=&#34;image-20220321160030395&#34;&gt;&lt;/p&gt;
&lt;p&gt;比如opencv的&lt;strong&gt;getPerspectiveTransform&lt;/strong&gt;方法，字面意思就是改变给定图像的透视图。（是在改变给定的&lt;strong&gt;一张图&lt;/strong&gt;，射影变换通常是在两张图之间寻求变换（相当于更换相机位置重新拍了一张图），比如&lt;a href=&#34;https://opencv24-python-tutorials.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_feature_homography/py_feature_homography.html&#34;&gt;opencv: Feature Matching + Homography to find Objects&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220323202307667.png&#34; alt=&#34;image-20220323202307667&#34;&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# In Perspective Transformation, we can change the perspective of a given image or video for getting better insights into the required information.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getPerspectiveTransform&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;method&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;Parameters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;src&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Coordinates&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;quadrangle&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;source&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;原图像四边形顶点&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;像素坐标&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dst&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Coordinates&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;of&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;corresponding&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;quadrangle&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vertices&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;destination&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;（&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;期望的目标图像四边形顶点&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;像素坐标&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;）&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;所以，应该从上下文理解意思，不要太纠结字眼。&lt;strong&gt;透视&lt;/strong&gt;一词来自的中心投影，比如相机成像、针孔模型、人眼。（通常）&lt;/p&gt;
&lt;p&gt;快速分辨透视变换与射影变换。（图3是图像拼接）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220323204243319.png&#34; alt=&#34;image-20220323204243319&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;《视觉SLAM14讲》中也给出类似定义：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321153212134.png&#34; alt=&#34;image-20220321153212134&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321153251128.png&#34; alt=&#34;image-20220321153251128&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;求解&#34;&gt;求解&lt;/h4&gt;
&lt;p&gt;齐次方程有8个自由度，需要8个线性方程组，一组对应点能提供两个方程，至少需要4组对应点。&lt;/p&gt;
&lt;p&gt;使用cv2.getPerspectiveTransform提供精准四组点对可以求得变换矩阵。&lt;/p&gt;
&lt;p&gt;在特征匹配的场合，对应点可能出现无匹配，并且匹配对数可能远大于4对，可以使用&lt;a href=&#34;https://blog.csdn.net/fengyeer20120/article/details/87798638&#34;&gt;cv2.findHomography&lt;/a&gt;，使用最小均方误差或者RANSAC方法优化输出结果。&lt;/p&gt;
&lt;h3 id=&#34;摄像机模型&#34;&gt;摄像机模型&lt;/h3&gt;
&lt;p&gt;摄像机模型已经比较清楚了，相关的常规一点的链接比如。&lt;a href=&#34;https://blog.csdn.net/weixin_43206570/article/details/84797361&#34;&gt;相机模型 16个参数&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考书内使用齐次坐标详细推导了摄像机模型P的形成。参考书 #6.1&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220322111246449.png&#34; alt=&#34;image-20220322111246449&#34;&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，P是将3D投影到2D，是3X4矩阵，所以P是作用到世界坐标上的，x=PX。所以，R和t也是从&lt;strong&gt;世界坐标系到相机坐标系&lt;/strong&gt;的转换（相机坐标系是中间过程）。
&lt;/p&gt;
$$
\widetilde{\mathbf{X}}_{\mathrm{cam}}=\mathrm{R}(\widetilde{\mathbf{X}}-\widetilde{\mathbf{C}})
$$
&lt;p&gt;
其中，C~代表摄像机中心在世界坐标系中的坐标。&lt;/p&gt;
&lt;h4 id=&#34;求解-1&#34;&gt;求解&lt;/h4&gt;
&lt;p&gt;通过相机标定流程获取相机矩阵。&lt;/p&gt;
&lt;p&gt;求解外参可以使用PnP方法。[^PnP（ Perspective-n-Point）]是求解 3D 到 2D 点对运动的方法。它描述了当知道 n 个 3D 空间点及其投影位置时，如何估计相机的位姿。如果两张图像中其中一张特征点的 3D 位置已知，那么&lt;strong&gt;最少只需 3 个点对&lt;/strong&gt;（需要至少一个额外点验证结果）就可以估计相机运动。&lt;/p&gt;
&lt;p&gt;opencv提供了solvePnP函数来解决此问题。点对比较多的时候可以使用solvePnPRansac()消除噪声，提高鲁棒性。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/qq_30815237/article/details/87606687&#34;&gt;相机标定（3） opencv中solvePnPRansac()和solvePnP()计算外参数&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;二视图几何&#34;&gt;二视图几何&lt;/h3&gt;
&lt;h4 id=&#34;基本矩阵&#34;&gt;基本矩阵&lt;/h4&gt;
&lt;p&gt;基本矩阵是对极几何的代数表示。&lt;/p&gt;
&lt;p&gt;它表示在第一幅图像上的一个&lt;strong&gt;点&lt;/strong&gt;到另一幅图像上与之对应的对&lt;strong&gt;极线&lt;/strong&gt;的映射。&lt;strong&gt;是点到直线的映射。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/827012-20170910104028476-1239104682.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性质&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321171505518.png&#34; alt=&#34;image-20220321171505518&#34;&gt;&lt;/p&gt;
&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/image-20220321172244630.png&#34; alt=&#34;image-20220321172244630&#34; style=&#34;zoom:90%;&#34; /&gt;
&lt;p&gt;&lt;strong&gt;求解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;书上有介绍使用8点法或者7点法等数学方法求解F，但那是在未知相机参数的情况下。在双目相机的应用中，相机标定后，可以很轻松的使用上面红线的公式求出基本矩阵F。&lt;/p&gt;
&lt;h4 id=&#34;本质矩阵&#34;&gt;本质矩阵&lt;/h4&gt;
&lt;p&gt;博客讲得比较清楚。&lt;a href=&#34;https://www.cnblogs.com/sunny-li/p/7500541.html&#34;&gt;二视图从运动到结构&amp;mdash;-对极几何和基础矩阵&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;博客是从本质矩阵E讲到基本矩阵F的，参考书是先将F再讲E，不同的切入而已。&lt;/p&gt;
&lt;p&gt;注意，叉乘转矩阵运算的方法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://hezhou-img.oss-cn-shanghai.aliyuncs.com/img/827012-20170911213138000-1685547295.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;由基本矩阵恢复E：
&lt;/p&gt;
$$
\mathrm{E}=\mathrm{K}^{\prime \top} \mathrm{FK}
$$
&lt;p&gt;
&lt;strong&gt;从无标定参数的二试图求解本质矩阵：&lt;/strong&gt;（14讲——本质矩阵）&lt;/p&gt;
&lt;p&gt;本质矩阵只有5个自由度，照理说最少只需要5组点对即可求解，但是比较麻烦，所以通常使用8点法求解（8组）。（从工程实现角度考虑，由于平时通常会有几十对乃至上百对的匹配点，从 8 对减至 5 对意义并不明显。）&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
